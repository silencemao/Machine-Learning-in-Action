{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用真实的数据来验证朴素贝叶斯 英文文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 准备数据, 生成词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 接收一段文字, 转换为字符串列表\n",
    "def txtParse(bigString):\n",
    "    listOfTokens = re.split('\\W*', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 去重, 生成词汇表\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将每一段输入文字转换为向量\n",
    "def bagOfWords2vecMN(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算贝叶斯分类器的各种先验概率\n",
    "def trainNB(trainMatrix, trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAb = sum(trainCategory) / float(numTrainDocs)\n",
    "    p0Num = np.ones(numWords)\n",
    "    p1Num = np.ones(numWords)\n",
    "    p0Denom = 2.0\n",
    "    p1Denom = 2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Denom += 1\n",
    "            p1Num += trainMatrix[i]\n",
    "        else:\n",
    "            p0Denom += 1\n",
    "            p0Num += trainMatrix[i]\n",
    "    p0Vec = np.log(p0Num / p1Denom)\n",
    "    p1Vec = np.log(p1Num / p1Denom)\n",
    "    return p0Vec, p1Vec, pAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 朴素贝叶斯分类器函数\n",
    "def classifyNB(vec2classify, p0Vec, p1Vec, pAb):\n",
    "    p0 = sum(vec2classify * p0Vec) + np.log(pAb)\n",
    "    p1 = sum(vec2classify * p1Vec) + np.log(pAb)\n",
    "    if p0 > p1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类错误的测试集 ['experience', 'with', 'biggerpenis', 'today', 'grow', '3', 'inches', 'more', 'the', 'safest', 'most', 'effective', 'methods', 'of_penisen1argement', 'save', 'your', 'time', 'and', 'money', 'bettererections', 'with', 'effective', 'ma1eenhancement', 'products', '1', 'ma1eenhancement', 'supplement', 'trusted', 'by', 'millions', 'buy', 'today', '']\n",
      "分类错误的测试集 ['oem', 'adobe', 'microsoft', 'softwares', 'fast', 'order', 'and', 'download', 'microsoft', 'office', 'professional', 'plus', '2007', '2010', '129', 'microsoft', 'windows', '7', 'ultimate', '119', 'adobe', 'photoshop', 'cs5', 'extended', 'adobe', 'acrobat', '9', 'pro', 'extended', 'windows', 'xp', 'professional', 'thousand', 'more', 'titles']\n",
      "错误率 20.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    docList = []\n",
    "    classList = []\n",
    "    for i in range(1, 26):\n",
    "        wordList = txtParse(open('./Machine-Learning-master/Naive Bayes/email/spam/%d.utf8.converted' % i, 'r').read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = txtParse(open('./Machine-Learning-master/Naive Bayes/email/ham/%d.utf8.converted' % i, 'r').read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = createVocabList(docList)\n",
    "    trainSet = list(range(50))\n",
    "    testSet = []\n",
    "    for i in range(10):\n",
    "        randIndex = int(r.random() * len(trainSet))\n",
    "        testSet.append(trainSet[randIndex])\n",
    "        del trainSet[randIndex]\n",
    "    trainMat = []\n",
    "    trainClasses = []\n",
    "    for docIndex in trainSet:\n",
    "        trainMat.append(bagOfWords2vecMN(vocabList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    p0V, p1V, pAb = trainNB(trainMat, trainClasses)\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:\n",
    "        word2Vec = bagOfWords2vecMN(vocabList, docList[docIndex])\n",
    "        if classifyNB(word2Vec, p0V, p1V, pAb) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "            print(\"分类错误的测试集\", docList[docIndex])\n",
    "    print(\"错误率 %.2f \" % (errorCount / len(testSet)*100) )\n",
    "#     print(vocabList) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
